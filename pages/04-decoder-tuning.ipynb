{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning d'un décodeur\n",
    "\n",
    "**Llama 3.2 avec la méthode LoRA (Low Rank Adaptation)**\n",
    "\n",
    "Dans notre projet, on mettra en place un décodeur Llama 3.2 afin de réaliser une tâche de classification. Llama 3.2 est un modèle de langage open-source développé par Meta (2024), il existe plusieurs versions de ce modèle. On utilisera la version 1B qui possède environ 1.24 milliard de paramètres, ce qui est suffisamment léger pour être fine-tuné sur un GPU grand public tout en restant performant pour des tâches comme la classification de texte. Afin d'améliorer l'efficacité de notre modèle, on utilisera la méthode LoRA. Elle permet d'adapter un grand modèle en n'entraînant qu'une fraction de ses paramètres (environ 1%). Au lieu de modifier tous les poids, on ajoute de petites matrices aux couches d'attention, ce qui réduit énormément le coût en mémoire et en temps d'exécution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:09.042098Z",
     "iopub.status.busy": "2026-01-04T22:00:09.041764Z",
     "iopub.status.idle": "2026-01-04T22:00:14.053928Z",
     "shell.execute_reply": "2026-01-04T22:00:14.053127Z",
     "shell.execute_reply.started": "2026-01-04T22:00:09.042063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "# transformers : pour charger Llama\n",
    "# peft : pour l'adaptation LoRA\n",
    "# trl : pour SFTTrainer (Supervised Fine-Tuning)\n",
    "!pip install -q transformers>=4.36.0 peft>=0.7.0 \\\n",
    "             datasets>=2.14.0 accelerate>=0.25.0 trl>=0.7.0 scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:14.055771Z",
     "iopub.status.busy": "2026-01-04T22:00:14.055518Z",
     "iopub.status.idle": "2026-01-04T22:00:15.734869Z",
     "shell.execute_reply": "2026-01-04T22:00:15.734294Z",
     "shell.execute_reply.started": "2026-01-04T22:00:14.055743Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Désactiver Weights & Biases (évite les problèmes de connexion)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWANDB_DISABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# manipulation de données\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# calculs numériques\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\api.py:28\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     isna,\n\u001b[0;32m     18\u001b[0m     isnull,\n\u001b[0;32m     19\u001b[0m     notna,\n\u001b[0;32m     20\u001b[0m     notnull,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     factorize,\n\u001b[0;32m     25\u001b[0m     unique,\n\u001b[0;32m     26\u001b[0m     value_counts,\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Categorical\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboolean\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BooleanDtype\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfloating\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     Float32Dtype,\n\u001b[0;32m     32\u001b[0m     Float64Dtype,\n\u001b[0;32m     33\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\__init__.py:19\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NumpyExtensionArray\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mperiod\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     PeriodArray,\n\u001b[0;32m     17\u001b[0m     period_array,\n\u001b[0;32m     18\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseArray\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringArray\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_arrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowStringArray\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     SparseAccessor,\n\u001b[0;32m      3\u001b[0m     SparseFrameAccessor,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     BlockIndex,\n\u001b[0;32m      7\u001b[0m     IntIndex,\n\u001b[0;32m      8\u001b[0m     SparseArray,\n\u001b[0;32m      9\u001b[0m     make_sparse_index,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparseFrameAccessor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\accessor.py:17\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     PandasDelegate,\n\u001b[0;32m     15\u001b[0m     delegate_names,\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseArray\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m         DataFrame,\n\u001b[0;32m     22\u001b[0m         Series,\n\u001b[0;32m     23\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\sparse\\array.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msplib\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     BlockIndex,\n\u001b[0;32m     25\u001b[0m     IntIndex,\n\u001b[0;32m     26\u001b[0m     SparseIndex,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NaT\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Désactiver Weights & Biases (évite les problèmes de connexion)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd  # manipulation de données\n",
    "import numpy as np  # calculs numériques\n",
    "import torch  # PyTorch\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm  # barre de progression\n",
    "\n",
    "# Transformers et PEFT\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "# Métriques d'évaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Vérification de la disponibilité du GPU\n",
    "print(f\"CUDA disponible : {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU : {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"Mémoire GPU : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} Go\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Authentification Hugging Face\n",
    "\n",
    "Llama 3.2 est un modèle \"gated\" nécessitant une authentification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:15.736014Z",
     "iopub.status.busy": "2026-01-04T22:00:15.735596Z",
     "iopub.status.idle": "2026-01-04T22:00:16.028309Z",
     "shell.execute_reply": "2026-01-04T22:00:16.027608Z",
     "shell.execute_reply.started": "2026-01-04T22:00:15.735994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Récupération du token depuis les secrets Kaggle\n",
    "hf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Chargement et Exploration des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:16.030106Z",
     "iopub.status.busy": "2026-01-04T22:00:16.029861Z",
     "iopub.status.idle": "2026-01-04T22:00:16.517963Z",
     "shell.execute_reply": "2026-01-04T22:00:16.517269Z",
     "shell.execute_reply.started": "2026-01-04T22:00:16.030086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 5010 exemples | Test : 2490 exemples\n",
      "\n",
      "Distribution des labels (train) :\n",
      "label\n",
      "contradiction    1670\n",
      "entailment       1670\n",
      "neutral          1670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Colonnes : ['-e premise', 'hypo', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Chemins vers les fichiers de données\n",
    "DATA_DIR = \"/kaggle/input/nli-french-dataset\"\n",
    "\n",
    "# Chargement des fichiers TSV\n",
    "df_train = pd.read_csv(f\"{DATA_DIR}/nli_fr_train.tsv\", sep=\"\\t\")\n",
    "df_test = pd.read_csv(f\"{DATA_DIR}/nli_fr_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Affichage des informations de base\n",
    "print(f\"Train : {len(df_train)} exemples | Test : {len(df_test)} exemples\")\n",
    "print(f\"\\nDistribution des labels (train) :\\n{df_train['label'].value_counts()}\")\n",
    "print(f\"\\nColonnes : {df_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:16.519783Z",
     "iopub.status.busy": "2026-01-04T22:00:16.519198Z",
     "iopub.status.idle": "2026-01-04T22:00:16.524170Z",
     "shell.execute_reply": "2026-01-04T22:00:16.523443Z",
     "shell.execute_reply.started": "2026-01-04T22:00:16.519760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes du DataFrame:\n",
      "['-e premise', 'hypo', 'label']\n",
      "\n",
      "Première ligne:\n",
      "-e premise    Eh bien, je ne pensais même pas à cela, mais j...\n",
      "hypo                          Je ne lui ai pas parlé de nouveau\n",
      "label                                             contradiction\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vérification des noms de colonnes et aperçu des données\n",
    "print(\"Colonnes du DataFrame:\")\n",
    "print(df_train.columns.tolist())\n",
    "print(\"\\nPremière ligne:\")\n",
    "print(df_train.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Préparation des Données\n",
    "\n",
    "Pour utiliser un **décodeur** (Llama) en classification, on reformule la tâche comme une génération de texte avec un prompt structuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:16.525365Z",
     "iopub.status.busy": "2026-01-04T22:00:16.525146Z",
     "iopub.status.idle": "2026-01-04T22:00:16.849625Z",
     "shell.execute_reply": "2026-01-04T22:00:16.849075Z",
     "shell.execute_reply.started": "2026-01-04T22:00:16.525347Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets préparés : 5010 train, 2490 test\n",
      "\n",
      "Exemple de prompt:\n",
      "### Instruction:\n",
      "Détermine la relation logique entre la Phrase 1 et la Phrase 2.\n",
      "Réponds uniquement par : entailment, contradiction, ou neutral.\n",
      "\n",
      "### Phrase 1:\n",
      "Eh bien, je ne pensais même pas à cela, mais j'étais si frustré, et j'ai fini par lui reparler.\n",
      "\n",
      "### Phrase 2:\n",
      "Je ne lui ai pas parlé de nou...\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(premise: str, hypothesis: str, label: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Crée un prompt formaté pour la tâche NLI.\n",
    "    Le format instruction/input/output est standard pour les LLMs.\n",
    "\n",
    "    Args:\n",
    "        premise: La première phrase (contexte)\n",
    "        hypothesis: La deuxième phrase (hypothèse à vérifier)\n",
    "        label: Le label attendu (pour l'entraînement)\n",
    "\n",
    "    Returns:\n",
    "        Le prompt formaté\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Détermine la relation logique entre la Phrase 1 et la Phrase 2.\n",
    "Réponds uniquement par : entailment, contradiction, ou neutral.\n",
    "\n",
    "### Phrase 1:\n",
    "{premise}\n",
    "\n",
    "### Phrase 2:\n",
    "{hypothesis}\n",
    "\n",
    "### Relation:\"\"\"\n",
    "\n",
    "    # Ajout du label pour l'entraînement\n",
    "    if label is not None:\n",
    "        prompt += f\" {label}\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prepare_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame pandas en Dataset Hugging Face.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame avec les colonnes premise, hypothesis, label\n",
    "\n",
    "    Returns:\n",
    "        Dataset Hugging Face prêt pour l'entraînement\n",
    "    \"\"\"\n",
    "    # Adaptation aux noms de colonnes du dataset\n",
    "    premise_col = \"premise\" if \"premise\" in df.columns else \"-e premise\"\n",
    "    hypo_col = \"hypo\" if \"hypo\" in df.columns else \"hypothesis\"\n",
    "\n",
    "    # Création des prompts pour chaque exemple\n",
    "    texts = [\n",
    "        create_prompt(row[premise_col], row[hypo_col], row[\"label\"])\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    return Dataset.from_dict({\"text\": texts, \"label\": df[\"label\"].tolist()})\n",
    "\n",
    "\n",
    "# Préparation des datasets\n",
    "train_dataset = prepare_dataset(df_train)\n",
    "test_dataset = prepare_dataset(df_test)\n",
    "\n",
    "print(f\"Datasets préparés : {len(train_dataset)} train, {len(test_dataset)} test\")\n",
    "print(f\"\\nExemple de prompt:\\n{train_dataset[0]['text'][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Chargement du Modèle Llama 3.2 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:16.850997Z",
     "iopub.status.busy": "2026-01-04T22:00:16.850515Z",
     "iopub.status.idle": "2026-01-04T22:00:29.959613Z",
     "shell.execute_reply": "2026-01-04T22:00:29.958859Z",
     "shell.execute_reply.started": "2026-01-04T22:00:16.850976Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdb272f3ff04217ae504aeaf4e5a63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ea846c201647d1b52313de2b59c527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b7b5402976437ba245871951b151e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d226bcb50fa485ba76061fe8cacdb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a26dd5c071040859244bb1c4a99add5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c752386dba164702bc96450a838ea823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé : 1,235,814,400 paramètres\n",
      "Mémoire GPU utilisée : 1.26 Go\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# Chargement du modèle en float16 (demi-précision pour économiser la mémoire)\n",
    "print(\"Chargement du modèle...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",  # Placement automatique sur GPU\n",
    "    torch_dtype=torch.float16,  # Précision 16-bit\n",
    "    token=hf_token,\n",
    ")\n",
    "\n",
    "# Chargement du tokenizer (convertit le texte en tokens)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Llama n'a pas de pad_token par défaut\n",
    "tokenizer.padding_side = \"right\"  # Padding à droite pour les décodeurs\n",
    "\n",
    "print(f\"Modèle chargé : {model.num_parameters():,} paramètres\")\n",
    "print(f\"Mémoire GPU utilisée : {torch.cuda.memory_allocated() / 1e9:.2f} Go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Configuration LoRA\n",
    "\n",
    "**LoRA** (Low-Rank Adaptation) permet d'adapter le modèle en n'entraînant qu'une fraction des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:29.960848Z",
     "iopub.status.busy": "2026-01-04T22:00:29.960585Z",
     "iopub.status.idle": "2026-01-04T22:00:30.116380Z",
     "shell.execute_reply": "2026-01-04T22:00:30.115798Z",
     "shell.execute_reply.started": "2026-01-04T22:00:29.960828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,407,872 || all params: 1,239,222,272 || trainable%: 0.2750\n"
     ]
    }
   ],
   "source": [
    "# Activation du gradient checkpointing pour économiser la mémoire\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Configuration des hyperparamètres LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rang des matrices d'adaptation\n",
    "    lora_alpha=32,  # Facteur de mise à l'échelle (alpha/r)\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Couches d'attention\n",
    "    lora_dropout=0.05,  # Dropout pour régularisation\n",
    "    bias=\"none\",  # Pas d'entraînement des biais\n",
    "    task_type=TaskType.CAUSAL_LM,  # Tâche de modélisation causale\n",
    ")\n",
    "\n",
    "# Application de LoRA au modèle\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Affichage du pourcentage de paramètres entraînables\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le rang r=16 offre un bon compromis entre un bon temps de calcul et efficacité, permettant de capturer suffisamment d'information pour la tâche NLI tout en gardant le nombre de paramètres entraînables faible (~0.27%). Le ratio alpha/r = 2 est une valeur standard qui stabilise l'apprentissage, et le ciblage des couches d'attention ('q_proj', 'k_proj', 'v_proj', 'o_proj') est recommandé car ce sont les couches les plus importantes pour adapter le comportement du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Entraînement (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:30.117478Z",
     "iopub.status.busy": "2026-01-04T22:00:30.117205Z",
     "iopub.status.idle": "2026-01-04T22:00:42.043754Z",
     "shell.execute_reply": "2026-01-04T22:00:42.043041Z",
     "shell.execute_reply.started": "2026-01-04T22:00:30.117452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7b2c30f29b4463a8590ffde6d8773e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/5010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8361cd3743234307a3d33c3bc63cfbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/5010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2178c796e4454e01a2230551d012357f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/5010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size effectif : 16\n",
      "Nombre de steps par epoch: 313\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"./llama-nli-lora\"\n",
    "\n",
    "# Configuration des paramètres d'entraînement\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=2,  # Nombre d'epochs\n",
    "    per_device_train_batch_size=4,  # Batch size par GPU\n",
    "    gradient_accumulation_steps=4,  # Accumulation pour batch effectif de 16\n",
    "    learning_rate=1e-4,  # Taux d'apprentissage\n",
    "    warmup_ratio=0.03,  # Warmup progressif\n",
    "    optim=\"adamw_torch\",  # Optimiseur AdamW\n",
    "    max_length=384,  # Longueur max des séquences\n",
    "    logging_steps=20,  # Fréquence des logs\n",
    "    logging_first_step=True,\n",
    "    save_strategy=\"no\",  # Pas de sauvegarde intermédiaire\n",
    "    fp16=True,  # Entraînement en précision mixte\n",
    "    dataset_text_field=\"text\",  # Colonne contenant les prompts\n",
    "    report_to=\"none\",  # Désactive wandb\n",
    "    gradient_checkpointing=True,  # Économie de mémoire\n",
    ")\n",
    "\n",
    "# Création du trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# Informations sur l'entraînement\n",
    "print(\n",
    "    f\"Batch size effectif : {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\"\n",
    ")\n",
    "print(\n",
    "    f\"Nombre de steps par epoch: {len(train_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le batch size effectif de 16 (4 × 4 accumulation) est adapté aux contraintes de limite de mémoire du GPU T4 en assurant des gradients assez stables. Le learning rate de '1e-4' est standard pour le fine-tuning LoRA, suffisamment élevé pour converger rapidement sur 2 epochs sans déstabiliser les poids pré-entraînés. Le warmup de 3% permet une montée progressive qui évite les mises à jour brutales tout au début de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:00:42.046117Z",
     "iopub.status.busy": "2026-01-04T22:00:42.045819Z",
     "iopub.status.idle": "2026-01-04T22:10:55.704610Z",
     "shell.execute_reply": "2026-01-04T22:10:55.704069Z",
     "shell.execute_reply.started": "2026-01-04T22:00:42.046097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement...\n",
      "Les logs apparaîtront toutes les 20 steps.\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='628' max='628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [628/628 10:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.795700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.246200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.213500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.207000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Entraînement terminé!\n",
      "Loss finale : 1.3066\n",
      "Temps total : 613 secondes\n"
     ]
    }
   ],
   "source": [
    "# Lancement de l'entraînement\n",
    "print(\"Début de l'entraînement...\")\n",
    "print(\"Les logs apparaîtront toutes les 20 steps.\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Entraînement terminé!\")\n",
    "print(f\"Loss finale : {train_result.training_loss:.4f}\")\n",
    "print(f\"Temps total : {train_result.metrics['train_runtime']:.0f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La loss diminue rapidement de 2.80 à ~1.30 dès les 40 premiers steps, indiquant que le modèle apprend efficacement le format de la tâche NLI. La stabilisation autour de 1.20-1.25 durant la deuxième epoch nous montre que le modèle a convergé et qu'un entraînement plus long n'apporterait pas d'amélioration significative sans risquer le surapprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:10:55.705712Z",
     "iopub.status.busy": "2026-01-04T22:10:55.705478Z",
     "iopub.status.idle": "2026-01-04T22:10:56.203142Z",
     "shell.execute_reply": "2026-01-04T22:10:56.202409Z",
     "shell.execute_reply.started": "2026-01-04T22:10:55.705694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé dans : ./llama-nli-lora\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du modèle fine-tuné (uniquement les poids LoRA)\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"Modèle sauvegardé dans : {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Évaluation du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:10:56.204441Z",
     "iopub.status.busy": "2026-01-04T22:10:56.204149Z",
     "iopub.status.idle": "2026-01-04T22:10:56.210653Z",
     "shell.execute_reply": "2026-01-04T22:10:56.209950Z",
     "shell.execute_reply.started": "2026-01-04T22:10:56.204408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_nli(model, tokenizer, premise: str, hypothesis: str) -> str:\n",
    "    \"\"\"\n",
    "    Prédit la relation NLI entre deux phrases.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle fine-tuné\n",
    "        tokenizer: Tokenizer associé\n",
    "        premise: Première phrase\n",
    "        hypothesis: Deuxième phrase\n",
    "\n",
    "    Returns:\n",
    "        Label prédit (entailment, contradiction, neutral)\n",
    "    \"\"\"\n",
    "    # Création du prompt sans label\n",
    "    prompt = create_prompt(premise, hypothesis)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Génération de la réponse\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False,  # Génération déterministe\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Décodage et extraction du label\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response.split(\"### Relation:\")[-1].strip().lower()\n",
    "\n",
    "    # Mapping vers les labels (gère les variations comme \"entail\")\n",
    "    if \"entail\" in response:\n",
    "        return \"entailment\"\n",
    "    elif \"contradict\" in response:\n",
    "        return \"contradiction\"\n",
    "    elif \"neutral\" in response:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:10:56.211730Z",
     "iopub.status.busy": "2026-01-04T22:10:56.211491Z",
     "iopub.status.idle": "2026-01-04T22:29:00.317733Z",
     "shell.execute_reply": "2026-01-04T22:29:00.316947Z",
     "shell.execute_reply.started": "2026-01-04T22:10:56.211704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation sur le jeu de test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bc9a7e404346bfb95117b5073a8c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "Caching is incompatible with gradient checkpointing in LlamaDecoderLayer. Setting `past_key_values=None`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation terminée.\n"
     ]
    }
   ],
   "source": [
    "# Prédictions sur le jeu de test\n",
    "print(\"Évaluation sur le jeu de test...\")\n",
    "\n",
    "# Adaptation aux noms de colonnes\n",
    "premise_col = \"premise\" if \"premise\" in df_test.columns else \"-e premise\"\n",
    "hypo_col = \"hypo\" if \"hypo\" in df_test.columns else \"hypothesis\"\n",
    "\n",
    "predictions = []\n",
    "true_labels = df_test[\"label\"].tolist()\n",
    "\n",
    "# Boucle de prédiction avec barre de progression\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    pred = predict_nli(model, tokenizer, row[premise_col], row[hypo_col])\n",
    "    predictions.append(pred)\n",
    "\n",
    "print(\"Évaluation terminée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Résultats et Métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:29:00.318907Z",
     "iopub.status.busy": "2026-01-04T22:29:00.318677Z",
     "iopub.status.idle": "2026-01-04T22:29:00.353966Z",
     "shell.execute_reply": "2026-01-04T22:29:00.353422Z",
     "shell.execute_reply.started": "2026-01-04T22:29:00.318887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RÉSULTATS - Llama 3.2 1B + LoRA\n",
      "==================================================\n",
      "\n",
      "Accuracy : 0.7080 (70.80%)\n",
      "\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction     0.7902    0.7217    0.7544       830\n",
      "   entailment     0.7198    0.7675    0.7429       830\n",
      "      neutral     0.6222    0.6349    0.6285       830\n",
      "\n",
      "     accuracy                         0.7080      2490\n",
      "    macro avg     0.7107    0.7080    0.7086      2490\n",
      " weighted avg     0.7107    0.7080    0.7086      2490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcul de l'accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"RÉSULTATS - Llama 3.2 1B + LoRA\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"\\nAccuracy : {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "print(f\"\\nRapport de classification :\")\n",
    "print(classification_report(true_labels, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy de 70.80% dépasse largement la baseline aléatoire (33%) et démontre l'efficacité du fine-tuning LoRA sur un décodeur pour une tâche de classification. La classe *neutral* obtient le F1-score le plus faible (0.63) car elle est plus ambiguë, ce qui est un phénomène classique en NLI où les frontières entre neutralité et implication/contradiction sont souvent floues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:29:00.354980Z",
     "iopub.status.busy": "2026-01-04T22:29:00.354731Z",
     "iopub.status.idle": "2026-01-04T22:29:00.763904Z",
     "shell.execute_reply": "2026-01-04T22:29:00.763366Z",
     "shell.execute_reply.started": "2026-01-04T22:29:00.354956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "labels = [\"entailment\", \"contradiction\", \"neutral\"]\n",
    "cm = confusion_matrix(true_labels, predictions, labels=labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels\n",
    ")\n",
    "plt.title(\"Matrice de Confusion - Llama 3.2 1B + LoRA\")\n",
    "plt.xlabel(\"Prédictions\")\n",
    "plt.ylabel(\"Labels réels\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que les erreurs se concentrent principalement entre *neutral* et les deux autres classes, confirmant la difficulté du modèle à distinguer les cas ambigus. Les classes *entailment* et *contradiction* sont relativement bien séparées entre elles, ce qui indique que le modèle a bien appris les relations logiques opposées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-04T22:29:00.764773Z",
     "iopub.status.busy": "2026-01-04T22:29:00.764583Z",
     "iopub.status.idle": "2026-01-04T22:29:00.794197Z",
     "shell.execute_reply": "2026-01-04T22:29:00.793499Z",
     "shell.execute_reply.started": "2026-01-04T22:29:00.764755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CONFIGURATION EXPÉRIMENTALE\n",
      "==================================================\n",
      "Modèle : Llama 3.2 1B\n",
      "LoRA : r=16, alpha=32\n",
      "Epochs : 2\n",
      "Learning rate : 0.0001\n",
      "Batch size : 16\n",
      "\n",
      "Accuracy finale : 70.80%\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde des prédictions dans un fichier CSV\n",
    "premise_col = \"premise\" if \"premise\" in df_test.columns else \"-e premise\"\n",
    "hypo_col = \"hypo\" if \"hypo\" in df_test.columns else \"hypothesis\"\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"premise\": df_test[premise_col],\n",
    "        \"hypothesis\": df_test[hypo_col],\n",
    "        \"true_label\": true_labels,\n",
    "        \"predicted\": predictions,\n",
    "        \"correct\": [t == p for t, p in zip(true_labels, predictions)],\n",
    "    }\n",
    ")\n",
    "results_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "# Résumé final de la configuration\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"CONFIGURATION EXPÉRIMENTALE\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Modèle : Llama 3.2 1B\")\n",
    "print(f\"LoRA : r={lora_config.r}, alpha={lora_config.lora_alpha}\")\n",
    "print(f\"Epochs : {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate : {training_args.learning_rate}\")\n",
    "print(\n",
    "    f\"Batch size : {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\"\n",
    ")\n",
    "print(f\"\\nAccuracy finale : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Résultats expérimentaux\n",
    "\n",
    "### 4.1 Données et configuration\n",
    "\n",
    "| **Paramètre** | **Valeur** |\n",
    "|---|---|\n",
    "| Modèle | Llama 3.2 1B |\n",
    "| Paramètres entraînables | 0.52% |\n",
    "| Epochs | 2 |\n",
    "| Batch size | 16 |\n",
    "| Learning rate | $1 \\times 10^{-4}$ |\n",
    "\n",
    "Ces hyperparamètres ont été choisis pour avoir un compromis entre un resultats satisfaisant et un temps de calcul efficace. \n",
    "\n",
    "### 4.2 Performances\n",
    "\n",
    "| **Classe** | **Precision** | **Recall** | **F1-score** | **Support** |\n",
    "|---|---|---|---|---|\n",
    "| Contradiction | 0.7902 | 0.7217 | 0.7544 | 830 |\n",
    "| Entailment | 0.7198 | 0.7675 | 0.7429 | 830 |\n",
    "| Neutral | 0.6222 | 0.6349 | 0.6285 | 830 |\n",
    "| **Accuracy** | – | – | **0.7080** | 2490 |\n",
    "| Macro avg | 0.7107 | 0.7080 | 0.7086 | 2490 |\n",
    "---\n",
    "\n",
    "Le modèle atteint une accuracy de **70.80%**, bien au-dessus de la baseline aléatoire (33.33%). Les classes *contradiction* et *entailment* obtiennent des F1-scores similaires (~0.75), tandis que la classe *neutral* présente des performances inférieures (F1 = 0.63), ce qui s'explique par sa nature plus ambiguë. En n'entraînant que 0.52% des paramètres, LoRA permet d'adapter efficacement un décodeur à une tâche de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Conclusion\n",
    "\n",
    "Ce projet a permis d'explorer la mise en place du modèle Llama 3.2 1B à la tâche d'inférence en langage naturel (NLI) en français en utilisant la méthode LoRA. Cette technique de fine-tuning nous a permis d'entraîner seulement 0.5% des paramètres du modèle tout en obtenant une accuracy de **70.80%**. On observe aussi que la classe *neutral* obtient un F1-score plus faible (0.63) que les classes *contradiction* et *entailment* (~0.75), une différence qui s'explique peut-être par l'ambiguïté de cette catégorie. Toutefois, ces résultats nous montrent qu'un décodeur autorégressif peut être adapté de manière satisfaisante à une tâche de classification sans nécessiter de ressources matérielles importantes."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9183878,
     "sourceId": 14380633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
