{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23532f8d",
   "metadata": {},
   "source": [
    "## Representation learning for NLP\n",
    "\n",
    "### Préparation des données\n",
    "Chargement du dataset et mappage des labels en entiers (0: Contradiction, 1: Neutre, 2: Conséquence).\n",
    "\n",
    "### Ajustement des encodeurs (classification multi-classes)\n",
    "- **Objectif :** Résoudre la tâche en utilisant LoRA\n",
    "- **Modèle :** CamemBERT 2.0 et CamemBERTa 2.0\n",
    "- **Étapes :** (pour chaque modèle)\n",
    "    * Chargement du modèle\n",
    "    * Configurer LoRA aux modules query/value\n",
    "    * Entraînement : Ajuster par apprentissage supervisé sur la tâche de classification.\n",
    "\n",
    "### Ajustement des décodeurs (génératif)\n",
    "- **Objectif :** Résoudre la tâche en utilisant un modèle génératif (LLM) avec LoRA.\n",
    "- **Modèles :** Llama 3 (modèle 1B ou 3B).\n",
    "- **Étapes :**\n",
    "    * Formatage : Convertir le jeu de données en format de prompt (ex: \"Prémisse : X. Hypothèse : Y. Relation : [MASK]\").\n",
    "    * Config LoRA : Appliquer LoRA au modèle Llama 3.\n",
    "    * Entraînement : Ajuster par apprentissage supervisé (Causal Language Modeling).\n",
    "    * Évaluation : Générer des réponses sur le jeu de test et mapper le texte de sortie aux étiquettes.\n",
    "\n",
    "### Apprentissage en contexte (prompt engineering)\n",
    "- **Objectif :** Évaluer Llama 3 (3B ou 8B) sans mettre à jour les poids (Inférence seule).\n",
    "- **Expériences :**\n",
    "    - **0-shot :** Demander au modèle de classer sans exemples.\n",
    "    - **Few-shot :** Fournir quelques exemples de prémisse/hypothèse/étiquette avant de demander la prédiction.\n",
    "    - **Chain-of-Thought (CoT) :** Prompter le modèle pour qu'il explique pourquoi il a choisi une étiquette. Cela répond à l'objectif pédagogique de compréhension du CoT.\n",
    "\n",
    "### Évaluation des modèles\n",
    "- matrice de confusion et métriques standard pour la classification multi-classes: accuracy, F1-score, weighted F1-score, precision, recall"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
